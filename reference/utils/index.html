
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://mindspore-lab.github.io/mindcv/reference/utils/">
      
      
        <link rel="prev" href="../scheduler/">
      
      
        <link rel="next" href="../../notes/changelog/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>utils - MindCV Docs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.2afb09e1.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#utility" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="MindCV Docs" class="md-header__button md-logo" aria-label="MindCV Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MindCV Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              utils
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="./" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="../../zh/reference/utils/" hreflang="zh" class="md-select__link">
              中文
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/mindspore-lab/mindcv" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindcv
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../installation/" class="md-tabs__link">
        
  
  
    
  
  Installation

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../modelzoo/" class="md-tabs__link">
        
  
  
    
  
  Model Zoo

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../tutorials/quick_start/" class="md-tabs__link">
          
  
  
    
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../how_to_guides/write_a_new_model/" class="md-tabs__link">
          
  
  
    
  
  How-To Guides

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../data/" class="md-tabs__link">
          
  
  
    
  
  Reference

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../notes/changelog/" class="md-tabs__link">
          
  
  
    
  
  Notes

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="MindCV Docs" class="md-nav__button md-logo" aria-label="MindCV Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    MindCV Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mindspore-lab/mindcv" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindcv
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Installation
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../modelzoo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Model Zoo
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tutorials
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/quick_start/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quick Start
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/configuration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Configuration
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/finetune/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Finetune
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Inference
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    How-To Guides
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            How-To Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../how_to_guides/write_a_new_model/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Write A New Model
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../how_to_guides/feature_extraction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Multi-Scale Feature Extraction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../how_to_guides/finetune_with_a_custom_dataset/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Fine-tune with A Custom Dataset
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Reference
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    data
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../loss/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    loss
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models.layers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    models.layers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optim/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    optim
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scheduler/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    scheduler
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    utils
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    utils
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#logger" class="md-nav__link">
    <span class="md-ellipsis">
      Logger
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Logger">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.logger.set_logger" class="md-nav__link">
    <span class="md-ellipsis">
      set_logger
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#callbacks" class="md-nav__link">
    <span class="md-ellipsis">
      Callbacks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Callbacks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.callbacks.StateMonitor" class="md-nav__link">
    <span class="md-ellipsis">
      StateMonitor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="StateMonitor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.callbacks.StateMonitor.apply_eval" class="md-nav__link">
    <span class="md-ellipsis">
      apply_eval
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.callbacks.StateMonitor.on_train_epoch_end" class="md-nav__link">
    <span class="md-ellipsis">
      on_train_epoch_end
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.callbacks.ValCallback" class="md-nav__link">
    <span class="md-ellipsis">
      ValCallback
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#train-step" class="md-nav__link">
    <span class="md-ellipsis">
      Train Step
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Train Step">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.train_step.TrainStep" class="md-nav__link">
    <span class="md-ellipsis">
      TrainStep
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer-factory" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer Factory
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Trainer Factory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.trainer_factory.create_trainer" class="md-nav__link">
    <span class="md-ellipsis">
      create_trainer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Notes
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notes/changelog/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Change Log
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notes/contributing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notes/code_of_conduct/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Code of Conduct
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../notes/faq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FAQ
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#logger" class="md-nav__link">
    <span class="md-ellipsis">
      Logger
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Logger">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.logger.set_logger" class="md-nav__link">
    <span class="md-ellipsis">
      set_logger
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#callbacks" class="md-nav__link">
    <span class="md-ellipsis">
      Callbacks
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Callbacks">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.callbacks.StateMonitor" class="md-nav__link">
    <span class="md-ellipsis">
      StateMonitor
    </span>
  </a>
  
    <nav class="md-nav" aria-label="StateMonitor">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.callbacks.StateMonitor.apply_eval" class="md-nav__link">
    <span class="md-ellipsis">
      apply_eval
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.callbacks.StateMonitor.on_train_epoch_end" class="md-nav__link">
    <span class="md-ellipsis">
      on_train_epoch_end
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.callbacks.ValCallback" class="md-nav__link">
    <span class="md-ellipsis">
      ValCallback
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#train-step" class="md-nav__link">
    <span class="md-ellipsis">
      Train Step
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Train Step">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.train_step.TrainStep" class="md-nav__link">
    <span class="md-ellipsis">
      TrainStep
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer-factory" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer Factory
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Trainer Factory">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindcv.utils.trainer_factory.create_trainer" class="md-nav__link">
    <span class="md-ellipsis">
      create_trainer
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/mindspore-lab/mindcv/edit/master/docs/en/reference/utils.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/mindspore-lab/mindcv/raw/master/docs/en/reference/utils.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="utility">Utility<a class="headerlink" href="#utility" title="Permanent link">&para;</a></h1>
<h2 id="logger">Logger<a class="headerlink" href="#logger" title="Permanent link">&para;</a></h2>


<div class="doc doc-object doc-function">


<h3 id="mindcv.utils.logger.set_logger" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindcv</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">set_logger</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">log_level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

<a href="#mindcv.utils.logger.set_logger" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents first">

        <p>Initialize the logger.</p>
<p>If the logger has not been initialized, this method will initialize the
logger by adding one or two handlers, otherwise the initialized logger will
be directly returned. During initialization, only logger of the master
process is added console handler. If <code>output_dir</code> is specified, all loggers
will be added file handler.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>name</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Logger name. Defaults to None to set up root logger.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[str]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>output_dir</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The directory to save log.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[str]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>rank</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Process rank in the distributed training. Defaults to 0.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>log_level</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Verbosity level of the logger. Defaults to <code>logging.INFO</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="logging.INFO">INFO</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>color</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>If True, color the output. Defaults to True.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="logging.Logger">Logger</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>logging.Logger: A initialized logger.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindcv/utils/logger.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">set_logger</span><span class="p">(</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">log_level</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">,</span>
    <span class="n">color</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">logging</span><span class="o">.</span><span class="n">Logger</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initialize the logger.</span>

<span class="sd">    If the logger has not been initialized, this method will initialize the</span>
<span class="sd">    logger by adding one or two handlers, otherwise the initialized logger will</span>
<span class="sd">    be directly returned. During initialization, only logger of the master</span>
<span class="sd">    process is added console handler. If ``output_dir`` is specified, all loggers</span>
<span class="sd">    will be added file handler.</span>

<span class="sd">    Args:</span>
<span class="sd">        name: Logger name. Defaults to None to set up root logger.</span>
<span class="sd">        output_dir: The directory to save log.</span>
<span class="sd">        rank: Process rank in the distributed training. Defaults to 0.</span>
<span class="sd">        log_level: Verbosity level of the logger. Defaults to ``logging.INFO``.</span>
<span class="sd">        color: If True, color the output. Defaults to True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        logging.Logger: A initialized logger.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">rank</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">rank</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">logger_initialized</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">logger_initialized</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

    <span class="c1"># get root logger if name is None</span>
    <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">log_level</span><span class="p">)</span>
    <span class="c1"># the messages of this logger will not be propagated to its parent</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">propagate</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="n">fmt</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%(asctime)s</span><span class="s2"> </span><span class="si">%(name)s</span><span class="s2"> </span><span class="si">%(levelname)s</span><span class="s2"> - </span><span class="si">%(message)s</span><span class="s2">&quot;</span>
    <span class="n">datefmt</span> <span class="o">=</span> <span class="s2">&quot;[%Y-%m-</span><span class="si">%d</span><span class="s2"> %H:%M:%S]&quot;</span>

    <span class="c1"># create console handler for master process</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">color</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">has_rich</span><span class="p">:</span>
                <span class="n">console_handler</span> <span class="o">=</span> <span class="n">RichHandler</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">log_level</span><span class="p">,</span> <span class="n">log_time_format</span><span class="o">=</span><span class="n">datefmt</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">has_termcolor</span><span class="p">:</span>
                <span class="n">console_handler</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">StreamHandler</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">)</span>
                <span class="n">console_handler</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">log_level</span><span class="p">)</span>
                <span class="n">console_handler</span><span class="o">.</span><span class="n">setFormatter</span><span class="p">(</span><span class="n">_ColorfulFormatter</span><span class="p">(</span><span class="n">fmt</span><span class="o">=</span><span class="n">fmt</span><span class="p">,</span> <span class="n">datefmt</span><span class="o">=</span><span class="n">datefmt</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;If you want color, &#39;rich&#39; or &#39;termcolor&#39; has to be installed!&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">console_handler</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">StreamHandler</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">)</span>
            <span class="n">console_handler</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">log_level</span><span class="p">)</span>
            <span class="n">console_handler</span><span class="o">.</span><span class="n">setFormatter</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">Formatter</span><span class="p">(</span><span class="n">fmt</span><span class="o">=</span><span class="n">fmt</span><span class="p">,</span> <span class="n">datefmt</span><span class="o">=</span><span class="n">datefmt</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">console_handler</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">output_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">file_handler</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">FileHandler</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;rank</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">.log&quot;</span><span class="p">))</span>
        <span class="n">file_handler</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">log_level</span><span class="p">)</span>
        <span class="n">file_handler</span><span class="o">.</span><span class="n">setFormatter</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">Formatter</span><span class="p">(</span><span class="n">fmt</span><span class="o">=</span><span class="n">fmt</span><span class="p">,</span> <span class="n">datefmt</span><span class="o">=</span><span class="n">datefmt</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">file_handler</span><span class="p">)</span>

    <span class="n">logger_initialized</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">logger</span>
    <span class="k">return</span> <span class="n">logger</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><h2 id="callbacks">Callbacks<a class="headerlink" href="#callbacks" title="Permanent link">&para;</a></h2>


<div class="doc doc-object doc-class">



<h3 id="mindcv.utils.callbacks.StateMonitor" class="doc doc-heading">
            <code>mindcv.utils.callbacks.StateMonitor</code>


<a href="#mindcv.utils.callbacks.StateMonitor" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindspore.train.Callback">Callback</span></code></p>


        <p>Train loss and validation accuracy monitor, after each epoch save the
best checkpoint file with the highest validation accuracy.</p>

              <details class="quote">
                <summary>Source code in <code>mindcv/utils/callbacks.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">StateMonitor</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train loss and validation accuracy monitor, after each epoch save the</span>
<span class="sd">    best checkpoint file with the highest validation accuracy.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">model_ema</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">last_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">dataset_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metric_name</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,),</span>
        <span class="n">val_interval</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">val_start_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">save_best_ckpt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">ckpt_save_dir</span><span class="o">=</span><span class="s2">&quot;./&quot;</span><span class="p">,</span>
        <span class="n">ckpt_save_interval</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">ckpt_save_policy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">ckpt_keep_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">summary_dir</span><span class="o">=</span><span class="s2">&quot;./&quot;</span><span class="p">,</span>
        <span class="n">log_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">rank_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">device_num</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_ema</span> <span class="o">=</span> <span class="n">model_ema</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span> <span class="o">=</span> <span class="n">last_epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_sink_mode</span> <span class="o">=</span> <span class="n">dataset_sink_mode</span>
        <span class="c1"># evaluation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_val</span> <span class="o">=</span> <span class="n">dataset_val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span> <span class="o">=</span> <span class="n">metric_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_interval</span> <span class="o">=</span> <span class="n">val_interval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_start_epoch</span> <span class="o">=</span> <span class="n">val_start_epoch</span>
        <span class="c1"># logging</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_res</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_best_ckpt</span> <span class="o">=</span> <span class="n">save_best_ckpt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_save_dir</span> <span class="o">=</span> <span class="n">ckpt_save_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_save_interval</span> <span class="o">=</span> <span class="n">ckpt_save_interval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_save_policy</span> <span class="o">=</span> <span class="n">ckpt_save_policy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_keep_max</span> <span class="o">=</span> <span class="n">ckpt_keep_max</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_manager</span> <span class="o">=</span> <span class="n">CheckpointManager</span><span class="p">(</span><span class="n">ckpt_save_policy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_save_policy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_need_flush_from_cache</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_dir</span> <span class="o">=</span> <span class="n">summary_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_interval</span> <span class="o">=</span> <span class="n">log_interval</span>
        <span class="c1"># system</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank_id</span> <span class="o">=</span> <span class="n">rank_id</span> <span class="k">if</span> <span class="n">rank_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device_num</span> <span class="o">=</span> <span class="n">device_num</span> <span class="k">if</span> <span class="n">rank_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_id</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">ckpt_save_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_save_dir</span><span class="p">,</span> <span class="s2">&quot;result.log&quot;</span><span class="p">)</span>
            <span class="n">log_line</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">s</span><span class="si">:</span><span class="s2">&lt;20</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;Epoch&quot;</span><span class="p">,</span> <span class="s2">&quot;TrainLoss&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">metric_name</span><span class="p">,</span> <span class="s2">&quot;TrainTime&quot;</span><span class="p">,</span> <span class="s2">&quot;EvalTime&quot;</span><span class="p">,</span> <span class="s2">&quot;TotalTime&quot;</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>  <span class="c1"># writing the title of result.log</span>
                <span class="n">fp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">log_line</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">all_reduce</span> <span class="o">=</span> <span class="n">AllReduceSum</span><span class="p">()</span>
        <span class="c1"># timestamp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_ts</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_ts</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_time_accum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># model_ema</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ema</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hyper_map</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">HyperMap</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">online_params</span> <span class="o">=</span> <span class="n">ParameterTuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train_network</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">swap_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">online_params</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="s2">&quot;swap&quot;</span><span class="p">,</span> <span class="s2">&quot;zeros&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span> <span class="o">=</span> <span class="n">SummaryRecord</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">summary_dir</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">exc_args</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">apply_eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Model evaluation, return validation accuracy.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ema</span><span class="p">:</span>
            <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hyper_map</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">assign</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">swap_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">online_params</span><span class="p">)</span>
            <span class="n">ema_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="n">net</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_network_from_cbp</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;ema&quot;</span><span class="p">):</span>
                    <span class="n">new_name</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;ema.&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">ema_dict</span><span class="p">[</span><span class="n">new_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span>
            <span class="n">load_param_into_net</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train_network</span><span class="o">.</span><span class="n">network</span><span class="p">,</span> <span class="n">ema_dict</span><span class="p">)</span>
            <span class="n">res_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_val</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hyper_map</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">assign</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">online_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">swap_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_val</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">res_array</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">res_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">res_array</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">res_array</span><span class="p">)</span>
            <span class="n">res_array</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_num</span>
        <span class="n">res_array</span> <span class="o">=</span> <span class="n">res_array</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">res_array</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_step_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_ts</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_ts</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">num_epochs</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">epoch_num</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">batch_num</span>
        <span class="c1"># num_steps = num_batches * num_epochs</span>
        <span class="c1"># cur_x start from 1, end at num_xs, range: [1, num_xs]</span>
        <span class="n">cur_step</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span> <span class="o">*</span> <span class="n">num_batches</span>
        <span class="n">cur_epoch</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span>
        <span class="n">cur_batch</span> <span class="o">=</span> <span class="p">(</span><span class="n">cur_step</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">num_batches</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">step_time_accum</span> <span class="o">+=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_ts</span>
        <span class="k">if</span> <span class="n">cur_batch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">cur_batch</span> <span class="o">==</span> <span class="n">num_batches</span> <span class="ow">or</span> <span class="n">cur_batch</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr_from_cbp</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_loss_from_cbp</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Epoch: [</span><span class="si">{</span><span class="n">cur_epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s2">], &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;batch: [</span><span class="si">{</span><span class="n">cur_batch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_batches</span><span class="si">}</span><span class="s2">], &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;lr: </span><span class="si">{</span><span class="n">lr</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;time: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">step_time_accum</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step_time_accum</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        After epoch, print train loss and val accuracy,</span>
<span class="sd">        save the best ckpt file with the highest validation accuracy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">num_epochs</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">epoch_num</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">batch_num</span>
        <span class="n">cur_step</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span> <span class="o">*</span> <span class="n">num_batches</span>
        <span class="n">cur_epoch</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span>
        <span class="n">cur_batch</span> <span class="o">=</span> <span class="p">(</span><span class="n">cur_step</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">num_batches</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">train_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_ts</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_loss_from_cbp</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>

        <span class="n">val_time</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="c1"># val while training if validation loader is not None</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dataset_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="n">cur_epoch</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_start_epoch</span>
            <span class="ow">and</span> <span class="p">(</span><span class="n">cur_epoch</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_start_epoch</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_interval</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="p">):</span>
            <span class="n">val_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_eval</span><span class="p">(</span><span class="n">run_context</span><span class="p">)</span>
            <span class="n">val_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">val_time</span>
            <span class="c1"># record val acc</span>
            <span class="n">metric_str</span> <span class="o">=</span> <span class="s2">&quot;Validation &quot;</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">)):</span>
                <span class="n">metric_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="n">metric_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;time: </span><span class="si">{</span><span class="n">val_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">metric_str</span><span class="p">)</span>
            <span class="c1"># save the best ckpt file</span>
            <span class="k">if</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_res</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_res</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span> <span class="o">=</span> <span class="n">cur_epoch</span>
                <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;=&gt; New best val acc: </span><span class="si">{</span><span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># save checkpoint</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_id</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_best_ckpt</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span> <span class="o">==</span> <span class="n">cur_epoch</span><span class="p">:</span>  <span class="c1"># always save ckpt if cur epoch got best acc</span>
                <span class="n">best_ckpt_save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_save_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_best.ckpt&quot;</span><span class="p">)</span>
                <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">cb_params</span><span class="o">.</span><span class="n">train_network</span><span class="p">,</span> <span class="n">best_ckpt_save_path</span><span class="p">,</span> <span class="n">async_save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">cur_epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_save_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">cur_epoch</span> <span class="o">==</span> <span class="n">num_epochs</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_need_flush_from_cache</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_flush_from_cache</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>
                <span class="c1"># save optim for resume</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_optimizer_from_cbp</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>
                <span class="n">optim_save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_save_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;optim_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.ckpt&quot;</span><span class="p">)</span>
                <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">optim_save_path</span><span class="p">,</span> <span class="n">async_save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="c1"># keep checkpoint files number equal max number.</span>
                <span class="n">ckpt_save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_save_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">cur_epoch</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">cur_batch</span><span class="si">}</span><span class="s2">.ckpt&quot;</span><span class="p">)</span>
                <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving model to </span><span class="si">{</span><span class="n">ckpt_save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_manager</span><span class="o">.</span><span class="n">save_ckpoint</span><span class="p">(</span>
                    <span class="n">cb_params</span><span class="o">.</span><span class="n">train_network</span><span class="p">,</span>
                    <span class="n">num_ckpt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_keep_max</span><span class="p">,</span>
                    <span class="n">metric</span><span class="o">=</span><span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="n">save_path</span><span class="o">=</span><span class="n">ckpt_save_path</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># logging</span>
        <span class="n">total_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_ts</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Total time since last epoch: </span><span class="si">{</span><span class="n">total_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">(train: </span><span class="si">{</span><span class="n">train_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, val: </span><span class="si">{</span><span class="n">val_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">)s, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;ETA: </span><span class="si">{</span><span class="p">(</span><span class="n">num_epochs</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">cur_epoch</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">total_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span>
        <span class="p">)</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_id</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
            <span class="n">log_line</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">s</span><span class="si">:</span><span class="s2">&lt;20</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="p">[</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cur_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="o">*</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">res</span><span class="p">],</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">train_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">val_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">total_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="p">]</span>
            <span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_file</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
                <span class="n">fp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">log_line</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># summary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s2">&quot;scalar&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;train_loss_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span>
                <span class="s2">&quot;scalar&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;val_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">cur_step</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Finish training!&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The best validation </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> is: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_res</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2"> at epoch </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_network_from_cbp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_sink_mode</span><span class="p">:</span>
            <span class="n">network</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">train_network</span><span class="o">.</span><span class="n">network</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">network</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">train_network</span>
        <span class="k">return</span> <span class="n">network</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_optimizer_from_cbp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">optimizer</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_sink_mode</span><span class="p">:</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">train_network</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">optimizer</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">train_network</span><span class="o">.</span><span class="n">optimizer</span>
        <span class="k">return</span> <span class="n">optimizer</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_lr_from_cbp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">):</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_optimizer_from_cbp</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;`global_step` of optimizer is less than 1. It seems to be a overflow at the first step. &quot;</span>
                <span class="s2">&quot;If you keep seeing this message, it means that the optimizer never actually called.&quot;</span>
            <span class="p">)</span>
            <span class="n">optim_step</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">((</span><span class="mi">0</span><span class="p">,),</span> <span class="n">ms</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># if the optimizer is successfully called, the global_step will actually be the value of next step.</span>
            <span class="n">optim_step</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">dynamic_lr</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CellList</span><span class="p">):</span>
                <span class="c1"># return the learning rates of the first parameter if dynamic_lr</span>
                <span class="n">lr</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">optim_step</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lr</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">(</span><span class="n">optim_step</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">learning_rate</span>
        <span class="k">return</span> <span class="n">lr</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_loss_from_cbp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get loss from the network output.</span>
<span class="sd">        Args:</span>
<span class="sd">            cb_params (_InternalCallbackParam): Callback parameters.</span>
<span class="sd">        Returns:</span>
<span class="sd">            Union[Tensor, None], if parse loss success, will return a Tensor value(shape is [1]), else return None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">net_outputs</span>
        <span class="k">if</span> <span class="n">output</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Can not find any output by this network, so SummaryCollector will not collect loss.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">)):</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">output</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="n">output</span><span class="p">:</span>
            <span class="c1"># If the output is a list, since the default network returns loss first,</span>
            <span class="c1"># we assume that the first one is loss.</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;The output type could not be identified, expect type is one of &quot;</span>
                <span class="s2">&quot;[int, float, Tensor, list, tuple], so no loss was recorded in SummaryCollector.&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()))</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_flush_from_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cb_params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Flush cache data to host if tensor is cache enable.&quot;&quot;&quot;</span>
        <span class="n">has_cache_params</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">train_network</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">cache_enable</span><span class="p">:</span>
                <span class="n">has_cache_params</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">Tensor</span><span class="p">(</span><span class="n">param</span><span class="p">)</span><span class="o">.</span><span class="n">flush_from_cache</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">has_cache_params</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_need_flush_from_cache</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h4 id="mindcv.utils.callbacks.StateMonitor.apply_eval" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindcv</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">StateMonitor</span><span class="o">.</span><span class="n">apply_eval</span><span class="p">(</span><span class="n">run_context</span><span class="p">)</span></code>

<a href="#mindcv.utils.callbacks.StateMonitor.apply_eval" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>Model evaluation, return validation accuracy.</p>

            <details class="quote">
              <summary>Source code in <code>mindcv/utils/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">apply_eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Model evaluation, return validation accuracy.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ema</span><span class="p">:</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyper_map</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">assign</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">swap_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">online_params</span><span class="p">)</span>
        <span class="n">ema_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">net</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_network_from_cbp</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;ema&quot;</span><span class="p">):</span>
                <span class="n">new_name</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;ema.&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">ema_dict</span><span class="p">[</span><span class="n">new_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span>
        <span class="n">load_param_into_net</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train_network</span><span class="o">.</span><span class="n">network</span><span class="p">,</span> <span class="n">ema_dict</span><span class="p">)</span>
        <span class="n">res_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_val</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyper_map</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">assign</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">online_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">swap_params</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">res_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_val</span><span class="p">,</span> <span class="n">dataset_sink_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">res_array</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">res_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_num</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">res_array</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">res_array</span><span class="p">)</span>
        <span class="n">res_array</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_num</span>
    <span class="n">res_array</span> <span class="o">=</span> <span class="n">res_array</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">res_array</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="mindcv.utils.callbacks.StateMonitor.on_train_epoch_end" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindcv</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">StateMonitor</span><span class="o">.</span><span class="n">on_train_epoch_end</span><span class="p">(</span><span class="n">run_context</span><span class="p">)</span></code>

<a href="#mindcv.utils.callbacks.StateMonitor.on_train_epoch_end" class="headerlink" title="Permanent link">&para;</a></h4>


    <div class="doc doc-contents ">

        <p>After epoch, print train loss and val accuracy,
save the best ckpt file with the highest validation accuracy.</p>

            <details class="quote">
              <summary>Source code in <code>mindcv/utils/callbacks.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    After epoch, print train loss and val accuracy,</span>
<span class="sd">    save the best ckpt file with the highest validation accuracy.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">epoch_num</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">batch_num</span>
    <span class="n">cur_step</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span> <span class="o">*</span> <span class="n">num_batches</span>
    <span class="n">cur_epoch</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_epoch_num</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span>
    <span class="n">cur_batch</span> <span class="o">=</span> <span class="p">(</span><span class="n">cur_step</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">num_batches</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="n">train_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_ts</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_loss_from_cbp</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>

    <span class="n">val_time</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># val while training if validation loader is not None</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="ow">and</span> <span class="n">cur_epoch</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_start_epoch</span>
        <span class="ow">and</span> <span class="p">(</span><span class="n">cur_epoch</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_start_epoch</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_interval</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="p">):</span>
        <span class="n">val_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_eval</span><span class="p">(</span><span class="n">run_context</span><span class="p">)</span>
        <span class="n">val_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">val_time</span>
        <span class="c1"># record val acc</span>
        <span class="n">metric_str</span> <span class="o">=</span> <span class="s2">&quot;Validation &quot;</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">)):</span>
            <span class="n">metric_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2">, &quot;</span>
        <span class="n">metric_str</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;time: </span><span class="si">{</span><span class="n">val_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">metric_str</span><span class="p">)</span>
        <span class="c1"># save the best ckpt file</span>
        <span class="k">if</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_res</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_res</span> <span class="o">=</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span> <span class="o">=</span> <span class="n">cur_epoch</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;=&gt; New best val acc: </span><span class="si">{</span><span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># save checkpoint</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_id</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_best_ckpt</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_epoch</span> <span class="o">==</span> <span class="n">cur_epoch</span><span class="p">:</span>  <span class="c1"># always save ckpt if cur epoch got best acc</span>
            <span class="n">best_ckpt_save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_save_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_best.ckpt&quot;</span><span class="p">)</span>
            <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">cb_params</span><span class="o">.</span><span class="n">train_network</span><span class="p">,</span> <span class="n">best_ckpt_save_path</span><span class="p">,</span> <span class="n">async_save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">cur_epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_save_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">cur_epoch</span> <span class="o">==</span> <span class="n">num_epochs</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_need_flush_from_cache</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_flush_from_cache</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>
            <span class="c1"># save optim for resume</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_optimizer_from_cbp</span><span class="p">(</span><span class="n">cb_params</span><span class="p">)</span>
            <span class="n">optim_save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_save_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;optim_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.ckpt&quot;</span><span class="p">)</span>
            <span class="n">save_checkpoint</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">optim_save_path</span><span class="p">,</span> <span class="n">async_save</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1"># keep checkpoint files number equal max number.</span>
            <span class="n">ckpt_save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_save_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">cur_epoch</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">cur_batch</span><span class="si">}</span><span class="s2">.ckpt&quot;</span><span class="p">)</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving model to </span><span class="si">{</span><span class="n">ckpt_save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_manager</span><span class="o">.</span><span class="n">save_ckpoint</span><span class="p">(</span>
                <span class="n">cb_params</span><span class="o">.</span><span class="n">train_network</span><span class="p">,</span>
                <span class="n">num_ckpt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_keep_max</span><span class="p">,</span>
                <span class="n">metric</span><span class="o">=</span><span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">save_path</span><span class="o">=</span><span class="n">ckpt_save_path</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="c1"># logging</span>
    <span class="n">total_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch_ts</span>
    <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Total time since last epoch: </span><span class="si">{</span><span class="n">total_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">(train: </span><span class="si">{</span><span class="n">train_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, val: </span><span class="si">{</span><span class="n">val_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">)s, &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;ETA: </span><span class="si">{</span><span class="p">(</span><span class="n">num_epochs</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">cur_epoch</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">total_time</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span>
    <span class="p">)</span>
    <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank_id</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="n">log_line</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">s</span><span class="si">:</span><span class="s2">&lt;20</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="p">[</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cur_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="o">*</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">res</span><span class="p">],</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">train_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">val_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">total_time</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_file</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">fp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">log_line</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># summary</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span><span class="s2">&quot;scalar&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;train_loss_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">add_value</span><span class="p">(</span>
            <span class="s2">&quot;scalar&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;val_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">summary_record</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="n">cur_step</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="mindcv.utils.callbacks.ValCallback" class="doc doc-heading">
            <code>mindcv.utils.callbacks.ValCallback</code>


<a href="#mindcv.utils.callbacks.ValCallback" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindspore.train.Callback">Callback</span></code></p>


              <details class="quote">
                <summary>Source code in <code>mindcv/utils/callbacks.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ValCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_interval</span> <span class="o">=</span> <span class="n">log_interval</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ts</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_eval_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
        <span class="n">cb_params</span> <span class="o">=</span> <span class="n">run_context</span><span class="o">.</span><span class="n">original_args</span><span class="p">()</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">batch_num</span>
        <span class="n">cur_step</span> <span class="o">=</span> <span class="n">cb_params</span><span class="o">.</span><span class="n">cur_step_num</span>

        <span class="k">if</span> <span class="n">cur_step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">cur_step</span> <span class="o">==</span> <span class="n">num_batches</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;batch: </span><span class="si">{</span><span class="n">cur_step</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">num_batches</span><span class="si">}</span><span class="s2">, time: </span><span class="si">{</span><span class="n">time</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">ts</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ts</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div><h2 id="train-step">Train Step<a class="headerlink" href="#train-step" title="Permanent link">&para;</a></h2>


<div class="doc doc-object doc-class">



<h3 id="mindcv.utils.train_step.TrainStep" class="doc doc-heading">
            <code>mindcv.utils.train_step.TrainStep</code>


<a href="#mindcv.utils.train_step.TrainStep" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindspore.nn.TrainOneStepWithLossScaleCell">TrainOneStepWithLossScaleCell</span></code></p>


        <p>Training step with loss scale.</p>


<details class="the-customized-trainonestepcell-also-supported-following-algorithms" open>
  <summary>The customized trainOneStepCell also supported following algorithms</summary>
  <ul>
<li>Exponential Moving Average (EMA)</li>
<li>Gradient Clipping</li>
<li>Gradient Accumulation</li>
</ul>
</details>
              <details class="quote">
                <summary>Source code in <code>mindcv/utils/train_step.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">TrainStep</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">TrainOneStepWithLossScaleCell</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Training step with loss scale.</span>

<span class="sd">    The customized trainOneStepCell also supported following algorithms:</span>
<span class="sd">        * Exponential Moving Average (EMA)</span>
<span class="sd">        * Gradient Clipping</span>
<span class="sd">        * Gradient Accumulation</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">network</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">scale_sense</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">ema</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">ema_decay</span><span class="o">=</span><span class="mf">0.9999</span><span class="p">,</span>
        <span class="n">clip_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">clip_value</span><span class="o">=</span><span class="mf">15.0</span><span class="p">,</span>
        <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TrainStep</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scale_sense</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ema</span> <span class="o">=</span> <span class="n">ema</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ema_decay</span> <span class="o">=</span> <span class="n">ema_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">updates</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_grad</span> <span class="o">=</span> <span class="n">clip_grad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_value</span> <span class="o">=</span> <span class="n">clip_value</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights_all</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">ParameterTuple</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ema_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_all</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="s2">&quot;ema&quot;</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">accumulate_grad</span> <span class="o">=</span> <span class="n">gradient_accumulation_steps</span> <span class="o">&gt;</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accumulate_grad</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulation</span> <span class="o">=</span> <span class="n">GradientAccumulation</span><span class="p">(</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_reducer</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">ema_update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">updates</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># ema factor is corrected by (1 - exp(-t/T)), where `t` means time and `T` means temperature.</span>
        <span class="n">ema_decay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema_decay</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">F</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">updates</span> <span class="o">/</span> <span class="mi">2000</span><span class="p">))</span>
        <span class="c1"># update trainable parameters</span>
        <span class="n">success</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyper_map</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">_ema_op</span><span class="p">,</span> <span class="n">ema_decay</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema_weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_all</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">success</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">construct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">):</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">scaling_sens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_sense</span>

        <span class="n">status</span><span class="p">,</span> <span class="n">scaling_sens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_overflow_check</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">scaling_sens</span><span class="p">)</span>

        <span class="n">scaling_sens_filled</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="o">*</span> <span class="n">F</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">scaling_sens</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">,</span> <span class="n">weights</span><span class="p">)(</span><span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="n">scaling_sens_filled</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyper_map</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">_grad_scale</span><span class="p">,</span> <span class="n">scaling_sens</span><span class="p">),</span> <span class="n">grads</span><span class="p">)</span>

        <span class="c1"># todo: When to clip grad? Do we need to clip grad after grad reduction? What if grad accumulation is needed?</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_grad</span><span class="p">:</span>
            <span class="n">grads</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">clip_by_global_norm</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">clip_norm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clip_value</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_scaling_manager</span><span class="p">:</span>  <span class="c1"># scale_sense = update_cell: Cell --&gt; TrainOneStepWithLossScaleCell.construct</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accumulate_grad</span><span class="p">:</span>
                <span class="c1"># todo: GradientAccumulation only call grad_reducer at the step where the accumulation is completed.</span>
                <span class="c1">#  So checking the overflow status is after gradient reduction, is this correct?</span>
                <span class="c1"># get the overflow buffer</span>
                <span class="n">cond</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_overflow_status</span><span class="p">(</span><span class="n">status</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
                <span class="n">overflow</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_loss_scale</span><span class="p">(</span><span class="n">cond</span><span class="p">)</span>
                <span class="c1"># if there is no overflow, do optimize</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">overflow</span><span class="p">:</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulation</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">:</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">depend</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema_update</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># apply grad reducer on grads</span>
                <span class="n">grads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_reducer</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
                <span class="c1"># get the overflow buffer</span>
                <span class="n">cond</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_overflow_status</span><span class="p">(</span><span class="n">status</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
                <span class="n">overflow</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_loss_scale</span><span class="p">(</span><span class="n">cond</span><span class="p">)</span>
                <span class="c1"># if there is no overflow, do optimize</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">overflow</span><span class="p">:</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">depend</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">(</span><span class="n">grads</span><span class="p">))</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">:</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">depend</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema_update</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># scale_sense = loss_scale: Tensor --&gt; TrainOneStepCell.construct</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accumulate_grad</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulation</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">grads</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad_reducer</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">depend</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">(</span><span class="n">grads</span><span class="p">))</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">depend</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema_update</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div><h2 id="trainer-factory">Trainer Factory<a class="headerlink" href="#trainer-factory" title="Permanent link">&para;</a></h2>


<div class="doc doc-object doc-function">


<h3 id="mindcv.utils.trainer_factory.create_trainer" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindcv</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">trainer_factory</span><span class="o">.</span><span class="n">create_trainer</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">amp_level</span><span class="p">,</span> <span class="n">amp_cast_list</span><span class="p">,</span> <span class="n">loss_scale_type</span><span class="p">,</span> <span class="n">loss_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ema</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ema_decay</span><span class="o">=</span><span class="mf">0.9999</span><span class="p">,</span> <span class="n">clip_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">clip_value</span><span class="o">=</span><span class="mf">15.0</span><span class="p">,</span> <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

<a href="#mindcv.utils.trainer_factory.create_trainer" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents first">

        <p>Create Trainer.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>network</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The backbone network to train, evaluate or predict.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindspore.nn.Cell">Cell</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>loss</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The function of calculating loss.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindspore.nn.Cell">Cell</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>optimizer</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The optimizer for training.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="mindspore.nn.Cell">Cell</span></code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>metrics</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The metrics for model evaluation.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Union">Union</span>[dict, set]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>amp_level</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The level of auto mixing precision training.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>amp_cast_list</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>At the cell level, custom casting the cell to FP16.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>loss_scale_type</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The type of loss scale.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>str</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>loss_scale</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The value of loss scale.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>drop_overflow_update</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to execute optimizer if there is an overflow.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ema</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to use exponential moving average of model weights.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ema_decay</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Decay factor for model weights moving average.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.9999</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>clip_grad</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>whether to gradient clip.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>bool</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>clip_value</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The value at which to clip gradients.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>15.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>gradient_accumulation_steps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Accumulate the gradients of n batches before update.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>int</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>mindspore.Model</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindcv/utils/trainer_factory.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">create_trainer</span><span class="p">(</span>
    <span class="n">network</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">,</span>
    <span class="n">loss</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Cell</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="nb">set</span><span class="p">],</span>
    <span class="n">amp_level</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">amp_cast_list</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">loss_scale_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">loss_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">drop_overflow_update</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">ema</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">ema_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9999</span><span class="p">,</span>
    <span class="n">clip_grad</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">clip_value</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">15.0</span><span class="p">,</span>
    <span class="n">gradient_accumulation_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create Trainer.</span>

<span class="sd">    Args:</span>
<span class="sd">        network: The backbone network to train, evaluate or predict.</span>
<span class="sd">        loss: The function of calculating loss.</span>
<span class="sd">        optimizer: The optimizer for training.</span>
<span class="sd">        metrics: The metrics for model evaluation.</span>
<span class="sd">        amp_level: The level of auto mixing precision training.</span>
<span class="sd">        amp_cast_list: At the cell level, custom casting the cell to FP16.</span>
<span class="sd">        loss_scale_type: The type of loss scale.</span>
<span class="sd">        loss_scale: The value of loss scale.</span>
<span class="sd">        drop_overflow_update: Whether to execute optimizer if there is an overflow.</span>
<span class="sd">        ema: Whether to use exponential moving average of model weights.</span>
<span class="sd">        ema_decay: Decay factor for model weights moving average.</span>
<span class="sd">        clip_grad: whether to gradient clip.</span>
<span class="sd">        clip_value: The value at which to clip gradients.</span>
<span class="sd">        gradient_accumulation_steps: Accumulate the gradients of n batches before update.</span>

<span class="sd">    Returns:</span>
<span class="sd">        mindspore.Model</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">loss_scale</span> <span class="o">&lt;</span> <span class="mf">1.0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Loss scale cannot be less than 1.0!&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">drop_overflow_update</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="n">loss_scale_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;dynamic&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;DynamicLossScale ALWAYS drop overflow!&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">gradient_accumulation_steps</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`gradient_accumulation_steps` must be &gt;= 1!&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">require_customized_train_step</span><span class="p">(</span><span class="n">ema</span><span class="p">,</span> <span class="n">clip_grad</span><span class="p">,</span> <span class="n">gradient_accumulation_steps</span><span class="p">,</span> <span class="n">amp_cast_list</span><span class="p">):</span>
        <span class="n">mindspore_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">network</span><span class="o">=</span><span class="n">network</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
            <span class="n">amp_level</span><span class="o">=</span><span class="n">amp_level</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">loss_scale_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;fixed&quot;</span><span class="p">:</span>
            <span class="n">mindspore_kwargs</span><span class="p">[</span><span class="s2">&quot;loss_scale_manager&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span>
                <span class="n">loss_scale</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="n">drop_overflow_update</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">loss_scale_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;dynamic&quot;</span><span class="p">:</span>
            <span class="n">mindspore_kwargs</span><span class="p">[</span><span class="s2">&quot;loss_scale_manager&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">DynamicLossScaleManager</span><span class="p">(</span>
                <span class="n">init_loss_scale</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale_window</span><span class="o">=</span><span class="mi">2000</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">loss_scale_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span><span class="p">:</span>
            <span class="c1"># We don&#39;t explicitly construct LossScaleManager</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;You are using AUTO loss scale, which means the LossScaleManager isn&#39;t explicitly pass in &quot;</span>
                <span class="s2">&quot;when creating a mindspore.Model instance. &quot;</span>
                <span class="s2">&quot;NOTE: mindspore.Model may use LossScaleManager silently. See mindspore.train.amp for details.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss scale type only support [&#39;fixed&#39;, &#39;dynamic&#39;, &#39;auto&#39;], but got</span><span class="si">{</span><span class="n">loss_scale_type</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="o">**</span><span class="n">mindspore_kwargs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>  <span class="c1"># require customized train step</span>
        <span class="n">eval_network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">WithEvalCell</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">amp_level</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;O2&quot;</span><span class="p">,</span> <span class="s2">&quot;O3&quot;</span><span class="p">,</span> <span class="s2">&quot;auto&quot;</span><span class="p">])</span>
        <span class="n">auto_mixed_precision</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">amp_level</span><span class="p">,</span> <span class="n">amp_cast_list</span><span class="p">)</span>
        <span class="n">net_with_loss</span> <span class="o">=</span> <span class="n">add_loss_network</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">amp_level</span><span class="p">)</span>
        <span class="n">train_step_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">network</span><span class="o">=</span><span class="n">net_with_loss</span><span class="p">,</span>
            <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">ema</span><span class="o">=</span><span class="n">ema</span><span class="p">,</span>
            <span class="n">ema_decay</span><span class="o">=</span><span class="n">ema_decay</span><span class="p">,</span>
            <span class="n">clip_grad</span><span class="o">=</span><span class="n">clip_grad</span><span class="p">,</span>
            <span class="n">clip_value</span><span class="o">=</span><span class="n">clip_value</span><span class="p">,</span>
            <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="n">gradient_accumulation_steps</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">loss_scale_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;fixed&quot;</span><span class="p">:</span>
            <span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">FixedLossScaleManager</span><span class="p">(</span><span class="n">loss_scale</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">drop_overflow_update</span><span class="o">=</span><span class="n">drop_overflow_update</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">loss_scale_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;dynamic&quot;</span><span class="p">:</span>
            <span class="n">loss_scale_manager</span> <span class="o">=</span> <span class="n">DynamicLossScaleManager</span><span class="p">(</span><span class="n">init_loss_scale</span><span class="o">=</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale_window</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loss scale type only support [&#39;fixed&#39;, &#39;dynamic&#39;], but got</span><span class="si">{</span><span class="n">loss_scale_type</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="n">update_cell</span> <span class="o">=</span> <span class="n">loss_scale_manager</span><span class="o">.</span><span class="n">get_update_cell</span><span class="p">()</span>
        <span class="c1"># 1. loss_scale_type=&quot;fixed&quot;, drop_overflow_update=False</span>
        <span class="c1"># --&gt; update_cell=None, TrainStep=TrainOneStepCell(scale_sense=loss_scale)</span>
        <span class="c1"># 2. loss_scale_type: fixed, drop_overflow_update: True</span>
        <span class="c1"># --&gt; update_cell=FixedLossScaleUpdateCell, TrainStep=TrainOneStepWithLossScaleCell(scale_sense=update_cell)</span>
        <span class="c1"># 3. loss_scale_type: dynamic, drop_overflow_update: True</span>
        <span class="c1"># --&gt; update_cell=DynamicLossScaleUpdateCell, TrainStep=TrainOneStepWithLossScaleCell(scale_sense=update_cell)</span>
        <span class="k">if</span> <span class="n">update_cell</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">train_step_kwargs</span><span class="p">[</span><span class="s2">&quot;scale_sense&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">loss_scale</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">context</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s2">&quot;enable_ge&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">context</span><span class="o">.</span><span class="n">get_context</span><span class="p">(</span><span class="s2">&quot;device_target&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;CPU&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Only `loss_scale_type` is `fixed` and `drop_overflow_update` is `False`&quot;</span>
                    <span class="s2">&quot;are supported on device `CPU`.&quot;</span>
                <span class="p">)</span>
            <span class="n">train_step_kwargs</span><span class="p">[</span><span class="s2">&quot;scale_sense&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">update_cell</span>
        <span class="n">train_step_cell</span> <span class="o">=</span> <span class="n">TrainStep</span><span class="p">(</span><span class="o">**</span><span class="n">train_step_kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">set_train</span><span class="p">()</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">train_step_cell</span><span class="p">,</span> <span class="n">eval_network</span><span class="o">=</span><span class="n">eval_network</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">eval_indexes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
        <span class="c1"># todo: do we need to set model._loss_scale_manager</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../scheduler/" class="md-footer__link md-footer__link--prev" aria-label="Previous: scheduler">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                scheduler
              </div>
            </div>
          </a>
        
        
          
          <a href="../../notes/changelog/" class="md-footer__link md-footer__link--next" aria-label="Next: Change Log">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Change Log
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 - 2023 MindSpore Lab
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="mailto:mindspore-lab@huawei.com" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/mindspore-lab/mindcv" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.zhihu.com/people/mindsporelab" target="_blank" rel="noopener" title="www.zhihu.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.indexes", "navigation.top", "navigation.footer", "toc.follow", "search.highlight", "search.share", "search.suggest", "content.action.view", "content.action.edit", "content.tabs.link", "content.code.copy", "content.code.select", "content.code.annotations"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>