# å¿«é€Ÿå…¥é—¨

æœ¬æ•™ç¨‹ä¸­æˆ‘ä»¬å°†æä¾›ä¸€ä¸ªå¿«é€Ÿä¸Šæ‰‹`mindcv`çš„æŒ‡å—ã€‚

æœ¬æ•™ç¨‹å°†ä»¥DenseNetåˆ†ç±»æ¨¡å‹ä¸ºä¾‹ï¼Œå®ç°å¯¹Cifar10æ•°æ®é›†çš„è¿ç§»å­¦ä¹ ï¼Œå¹¶åœ¨æ­¤æµç¨‹ä¸­å¯¹MindCVå„æ¨¡å—çš„ç”¨æ³•ä½œè®²è§£ã€‚



## ç¯å¢ƒå‡†å¤‡

### å®‰è£…MindCV


```python
# instal mindcv from git repo
!pip install git+https://github.com/mindlab-ai/mindcv.git
```

    Looking in indexes: http://mirrors.aliyun.com/pypi/simple
    Collecting git+https://github.com/mindlab-ai/mindcv.git
      Cloning https://github.com/mindlab-ai/mindcv.git to /tmp/pip-req-build-2t1sum4n
      Running command git clone --filter=blob:none --quiet https://github.com/mindlab-ai/mindcv.git /tmp/pip-req-build-2t1sum4n
      Resolved https://github.com/mindlab-ai/mindcv.git to commit 81fa3df8a7292c03b2a69b1456dadcfbe7ae9b9c
      Preparing metadata (setup.py) ... [?25ldone
    [?25hRequirement already satisfied: numpy>=1.17.0 in /opt/conda/envs/xgraph/lib/python3.8/site-packages (from mindcv==0.0.1) (1.22.4)
    Requirement already satisfied: PyYAML>=5.3 in /opt/conda/envs/xgraph/lib/python3.8/site-packages (from mindcv==0.0.1) (5.4)
    Requirement already satisfied: tqdm in /opt/conda/envs/xgraph/lib/python3.8/site-packages (from mindcv==0.0.1) (4.59.0)
    [33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
    [0m

> ä»¥ä¸‹æ•™ç¨‹å‡è®¾ä¾èµ–åŒ…å‡å·²å®‰è£…ï¼Œè‹¥é‡åˆ°ä¾èµ–é—®é¢˜ï¼Œè¯·æŒ‰ç…§Git repoä¸Šçš„[å®‰è£…æŒ‡å—](https://github.com/mindlab-ai/mindcv#dependency)è¿›è¡Œå®‰è£…

## æ•°æ®é›†è¯»å–

é€šè¿‡`mindcv.data`ä¸­çš„`create_dataset`æ¨¡å—ï¼Œæˆ‘ä»¬å¯å¿«é€Ÿåœ°è¯»å–æ ‡å‡†æ•°æ®é›†æˆ–è‡ªå®šä¹‰çš„æ•°æ®é›†ã€‚


```python
from mindcv.data import create_dataset, create_transforms, create_loader
import os

# æ•°æ®é›†è·¯å¾„
cifar10_dir = './datasets/cifar/cifar-10-batches-bin' # ä½ çš„æ•°æ®å­˜æ”¾è·¯å¾„
num_classes = 10 # ç±»åˆ«æ•°
num_workers = 8 # æ•°æ®è¯»å–åŠåŠ è½½çš„å·¥ä½œçº¿ç¨‹æ•° 
download = not os.path.exists(cifar10_dir)

# åˆ›å»ºæ•°æ®é›†
dataset_train = create_dataset(name='cifar10', root=cifar10_dir, split='train', shuffle=True, num_parallel_workers=num_workers, download=download)
```

`create_dataset`å‚æ•°è¯´æ˜:

- name: æ•°æ®é›†åç§°

- dataset_dir: åŒ…å«æ•°æ®é›†æ–‡ä»¶çš„æ ¹ç›®å½•è·¯å¾„ã€‚

- split: è¯»å–æ•°æ®é›†çš„è®­ç»ƒé›†ï¼ˆ"train"ï¼‰æˆ–éªŒè¯é›†ï¼ˆ"val"ï¼‰ã€‚é»˜è®¤å€¼ï¼š"train"ã€‚

- shuffle: æ˜¯å¦æ··æ´—æ•°æ®é›†ã€‚é»˜è®¤å€¼ï¼šNoneã€‚

- num_parallel_workers: æŒ‡å®šè¯»å–æ•°æ®çš„å·¥ä½œçº¿ç¨‹æ•°ã€‚é»˜è®¤å€¼ï¼šNoneã€‚

- download: æ˜¯å¦ä¸‹è½½æ•°æ®é›†ã€‚é»˜è®¤å€¼ï¼šFalseã€‚


## æ•°æ®å¤„ç†åŠåŠ è½½
1. é€šè¿‡`create_transforms`å‡½æ•°, å¯ç›´æ¥å¾—åˆ°æ ‡å‡†æ•°æ®é›†åˆé€‚çš„æ•°æ®å¤„ç†å¢å¼ºç­–ç•¥(transform list)ï¼ŒåŒ…æ‹¬Cifar10, imagenetä¸Šå¸¸ç”¨çš„æ•°æ®å¤„ç†ç­–ç•¥ã€‚


```python
# åˆ›å»ºæ‰€éœ€çš„æ•°æ®å¢å¼ºæ“ä½œçš„åˆ—è¡¨
trans = create_transforms(dataset_name='cifar10', image_resize=224)
```

`create_transforms`å‚æ•°è¯´æ˜:

- name: æ•°æ®é›†åç§°

- dataset_dir: åŒ…å«æ•°æ®é›†æ–‡ä»¶çš„æ ¹ç›®å½•è·¯å¾„ã€‚

- split: è¯»å–æ•°æ®é›†çš„è®­ç»ƒé›†ï¼ˆ"train"ï¼‰æˆ–éªŒè¯é›†ï¼ˆ"val"ï¼‰ã€‚é»˜è®¤å€¼ï¼š"train"ã€‚

- shuffle: æ˜¯å¦æ··æ´—æ•°æ®é›†ã€‚é»˜è®¤å€¼ï¼šNoneã€‚

- num_parallel_workers: æŒ‡å®šè¯»å–æ•°æ®çš„å·¥ä½œçº¿ç¨‹æ•°ã€‚é»˜è®¤å€¼ï¼šNoneã€‚

- download: æ˜¯å¦ä¸‹è½½æ•°æ®é›†ã€‚é»˜è®¤å€¼ï¼šFalseã€‚

2. é€šè¿‡`mindcv.data.create_loader`å‡½æ•°ï¼Œè¿›è¡Œæ•°æ®è½¬æ¢å’Œbatchåˆ‡åˆ†åŠ è½½ï¼Œæˆ‘ä»¬éœ€è¦å°†`create_transform`è¿”å›çš„transform_listä¼ å…¥ã€‚


```python
# æ‰§è¡Œæ•°æ®å¢å¼ºæ“ä½œï¼Œç”Ÿæˆæ‰€éœ€æ•°æ®é›†ã€‚
loader_train = create_loader(dataset=dataset_train,
                             batch_size=64,
                             is_training=True,
                             num_classes=num_classes,
                             transform=trans,
                             num_parallel_workers=num_workers)

num_batches = loader_train.get_dataset_size()
```

`create_loader`å‚æ•°è¯´æ˜:

- dataset: é€šè¿‡æ ‡å‡†æ•°æ®é›†æ¥å£ï¼ˆmindspore.dataset.Cifar10Datasetï¼Œmindspore.dataset.CocoDatasetï¼‰æˆ–è€…è‡ªå®šä¹‰æ•°æ®é›†æ¥å£ï¼ˆmindspore.dataset.GeneratorDatasetï¼‰åŠ è½½è¿‡çš„æ•°æ®é›†ã€‚

- batch_size: æŒ‡å®šæ¯ä¸ªæ‰¹å¤„ç†æ•°æ®åŒ…å«çš„æ•°æ®æ¡ç›®ã€‚

- is_training: è¯»å–æ•°æ®é›†çš„è®­ç»ƒé›†ï¼ˆTrueï¼‰æˆ–éªŒè¯é›†ï¼ˆFalseï¼‰ã€‚é»˜è®¤å€¼ï¼šFalseã€‚

- num_classes: åˆ†ç±»çš„ç±»åˆ«æ•°ã€‚é»˜è®¤å€¼ï¼š1000ã€‚
    
- transform: æ‰€éœ€çš„æ•°æ®å¢å¼ºæ“ä½œçš„åˆ—è¡¨ã€‚é»˜è®¤å€¼ï¼šNoneã€‚

- num_parallel_workers: æŒ‡å®šè¯»å–æ•°æ®çš„å·¥ä½œçº¿ç¨‹æ•°ã€‚é»˜è®¤å€¼ï¼šNoneã€‚


> åœ¨notebookä¸­é¿å…é‡å¤æ‰§è¡Œ`create_loader`å•ä¸ªCellï¼Œæˆ–åœ¨æ‰§è¡Œ`create_dataset`ä¹‹åå†æ¬¡æ‰§è¡Œ

## æ¨¡å‹åˆ›å»ºå’ŒåŠ è½½

ä½¿ç”¨`create_model`æ¥å£è·å¾—å®ä¾‹åŒ–çš„DenseNetï¼Œå¹¶åŠ è½½é¢„è®­ç»ƒæƒé‡densenet_121_imagenet2012.ckptï¼ˆImageNetæ•°æ®é›†è®­ç»ƒå¾—åˆ°ï¼‰ã€‚




```python
from mindcv.models import create_model

# å®ä¾‹åŒ– DenseNet-121 æ¨¡å‹å¹¶åŠ è½½é¢„è®­ç»ƒæƒé‡ã€‚
network = create_model(model_name='densenet121', num_classes=num_classes, pretrained=True)
```

    [WARNING] ME(57165:140402355906368,MainProcess):2022-09-22-09:08:11.784.095 [mindspore/train/serialization.py:709] For 'load_param_into_net', 2 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint.
    [WARNING] ME(57165:140402355906368,MainProcess):2022-09-22-09:08:11.785.187 [mindspore/train/serialization.py:714] classifier.weight is not loaded.
    [WARNING] ME(57165:140402355906368,MainProcess):2022-09-22-09:08:11.785.831 [mindspore/train/serialization.py:714] classifier.bias is not loaded.
    

> ç”±äºCifar10å’ŒImageNetæ•°æ®é›†æ‰€éœ€ç±»åˆ«æ•°é‡ä¸åŒï¼Œåˆ†ç±»å™¨å‚æ•°æ— æ³•å…±äº«ï¼Œå‡ºç°åˆ†ç±»å™¨å‚æ•°æ— æ³•åŠ è½½çš„å‘Šè­¦ä¸å½±å“å¾®è°ƒã€‚

`create_model`å‚æ•°è¯´æ˜:

- model_name: éœ€è¦åŠ è½½çš„æ¨¡å‹çš„è§„æ ¼çš„åç§°ã€‚

- num_classes: åˆ†ç±»çš„ç±»åˆ«æ•°ã€‚é»˜è®¤å€¼ï¼š1000ã€‚

- pretrained: æ˜¯å¦åŠ è½½ä¸è®­ç»ƒæƒé‡ã€‚é»˜è®¤å€¼ï¼šFalseã€‚

ä½¿ç”¨`mindcv.loss.create_loss`æ¥å£åˆ›å»ºæŸå¤±å‡½æ•°ï¼ˆcross_entropy lossï¼‰ã€‚

## æ¨¡å‹è®­ç»ƒ

é€šè¿‡`create_loss`æ¥å£è·å¾—æŸå¤±å‡½æ•°


```python
from mindcv.loss import create_loss

loss = create_loss(name='CE')
```

ä½¿ç”¨`create_scheduler`æ¥å£è®¾ç½®å­¦ä¹ ç‡ç­–ç•¥ï¼ˆwarmup_consine_decayï¼‰ã€‚


```python
from mindcv.scheduler import create_scheduler

# è®¾ç½®å­¦ä¹ ç‡ç­–ç•¥
lr_scheduler = create_scheduler(steps_per_epoch=num_batches,
                                scheduler='constant',
                                lr=0.0001)
```

å‚æ•°è¯´æ˜:

- steps_pre_epoch: å®Œæˆä¸€è½®è®­ç»ƒæ‰€éœ€è¦çš„æ­¥æ•°ã€‚

- scheduler: å­¦ä¹ ç‡ç­–ç•¥çš„åç§°ã€‚

- lr: å­¦ä¹ ç‡ã€‚

- min_lr: decayæ—¶å­¦ä¹ ç‡çš„æœ€å°å€¼ã€‚

ä½¿ç”¨`create_optimizer`æ¥å£åˆ›å»ºä¼˜åŒ–å™¨ã€‚


```python
from mindcv.optim import create_optimizer

# è®¾ç½®ä¼˜åŒ–å™¨
opt = create_optimizer(network.trainable_params(), opt='adam', lr=lr_scheduler) 
```

å‚æ•°è¯´æ˜:

- params: éœ€è¦ä¼˜åŒ–çš„å‚æ•°çš„åˆ—è¡¨ã€‚

- scheduler: å­¦ä¹ äº†ç­–ç•¥çš„åç§°ã€‚

- lr: å­¦ä¹ ç‡çš„æœ€å¤§å€¼ã€‚

- min_lr: å­¦ä¹ ç‡çš„æœ€å°å€¼ã€‚


ä½¿ç”¨[mindspore.Model](https://mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore/mindspore.Model.html)æ¥å£æ ¹æ®ç”¨æˆ·ä¼ å…¥çš„å‚æ•°å°è£…å¯è®­ç»ƒçš„å®ä¾‹ã€‚


```python
from mindspore import Model

# å°è£…å¯è®­ç»ƒæˆ–æ¨ç†çš„å®ä¾‹
model = Model(network, loss_fn=loss, optimizer=opt, metrics={'accuracy'})
```

ä½¿ç”¨[`mindspore.Model.train`](https://mindspore.cn/docs/zh-CN/r1.8/api_python/mindspore/mindspore.Model.html#mindspore.Model.train)æ¥å£è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚


```python
from mindspore import LossMonitor, TimeMonitor, CheckpointConfig, ModelCheckpoint

# è®¾ç½®åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜ç½‘ç»œå‚æ•°çš„å›è°ƒå‡½æ•°
ckpt_save_dir = './ckpt' 
ckpt_config = CheckpointConfig(save_checkpoint_steps=num_batches)
ckpt_cb = ModelCheckpoint(prefix='densenet121-cifar10',
                          directory=ckpt_save_dir,
                          config=ckpt_config)

model.train(5, loader_train, callbacks=[LossMonitor(num_batches//5), TimeMonitor(num_batches//5), ckpt_cb], dataset_sink_mode=False)
```

    epoch: 1 step: 156, loss is 0.36890333890914917
    epoch: 1 step: 312, loss is 0.2963641285896301
    epoch: 1 step: 468, loss is 0.08654475212097168
    epoch: 1 step: 624, loss is 0.1908271610736847
    epoch: 1 step: 780, loss is 0.1770080029964447
    Train epoch time: 262146.330 ms, per step time: 335.225 ms
    epoch: 2 step: 154, loss is 0.04639885947108269
    epoch: 2 step: 310, loss is 0.12687519192695618
    epoch: 2 step: 466, loss is 0.03369298204779625
    epoch: 2 step: 622, loss is 0.12257681041955948
    epoch: 2 step: 778, loss is 0.13823091983795166
    Train epoch time: 237231.079 ms, per step time: 303.365 ms
    epoch: 3 step: 152, loss is 0.03291231021285057
    epoch: 3 step: 308, loss is 0.04826178774237633
    epoch: 3 step: 464, loss is 0.06561325490474701
    epoch: 3 step: 620, loss is 0.028005748987197876
    epoch: 3 step: 776, loss is 0.14322009682655334
    Train epoch time: 240640.121 ms, per step time: 307.724 ms
    epoch: 4 step: 150, loss is 0.04635673016309738
    epoch: 4 step: 306, loss is 0.006769780069589615
    epoch: 4 step: 462, loss is 0.07550926506519318
    epoch: 4 step: 618, loss is 0.007201619446277618
    epoch: 4 step: 774, loss is 0.02128467708826065
    Train epoch time: 244391.659 ms, per step time: 312.521 ms
    epoch: 5 step: 148, loss is 0.00641212984919548
    epoch: 5 step: 304, loss is 0.013159077614545822
    epoch: 5 step: 460, loss is 0.021671295166015625
    epoch: 5 step: 616, loss is 0.01827814429998398
    epoch: 5 step: 772, loss is 0.008501190692186356
    Train epoch time: 240139.144 ms, per step time: 307.083 ms
    


```python
# åŠ è½½éªŒè¯æ•°æ®é›†
dataset_val = create_dataset(name='cifar10', root=cifar10_dir, split='test', shuffle=True, num_parallel_workers=num_workers, download=download)

# æ‰§è¡Œæ•°æ®å¢å¼ºæ“ä½œï¼Œç”Ÿæˆæ‰€éœ€æ•°æ®é›†ã€‚
loader_val = create_loader(dataset=dataset_val,
                           batch_size=64,
                           is_training=False,
                           num_classes=num_classes,
                           transform=trans,
                           num_parallel_workers=num_workers)
```

åŠ è½½å¾®è°ƒåçš„å‚æ•°æ–‡ä»¶ï¼ˆdensenet-cifar10-10_782.ckptï¼‰åˆ°æ¨¡å‹ã€‚

æ ¹æ®ç”¨æˆ·ä¼ å…¥çš„å‚æ•°å°è£…å¯æ¨ç†çš„å®ä¾‹ï¼ŒåŠ è½½éªŒè¯æ•°æ®é›†ï¼ŒéªŒè¯å¾®è°ƒçš„ DenseNet121æ¨¡å‹ç²¾åº¦ã€‚


```python
# éªŒè¯å¾®è°ƒåçš„DenseNet-121çš„ç²¾åº¦
acc = model.eval(loader_val, dataset_sink_mode=False)
print(acc)
```

    {'accuracy': 0.9577}
    

## ä½¿ç”¨YAMLæ–‡ä»¶è¿›è¡Œæ¨¡å‹è®­ç»ƒå’ŒéªŒè¯

æˆ‘ä»¬è¿˜å¯ä»¥ç›´æ¥ä½¿ç”¨è®¾ç½®å¥½æ¨¡å‹å‚æ•°çš„yamlæ–‡ä»¶ï¼Œé€šè¿‡`train.py`å’Œ`validate.py`è„šæœ¬æ¥å¿«é€Ÿæ¥å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ã€‚ä»¥ä¸‹æ˜¯åœ¨ImageNetä¸Šè®­ç»ƒSqueezenetV1çš„ç¤ºä¾‹ ï¼ˆéœ€è¦å°†imagenetæå‰ä¸‹è½½åˆ°ç›®å½•ä¸‹ï¼‰

> è¯¦ç»†æ•™ç¨‹è¯·å‚è€ƒ [ä½¿ç”¨yamlæ–‡ä»¶çš„æ•™ç¨‹](./learn_about_config.ipynb)




```python
!git clone https://github.com/mindlab-ai/mindcv.git
!cd mindcv
```


```python
!python train.py -c configs/squeezenet/squeezenet_1.0_gpu.yaml 
```


```python
!python validate.py -c configs/squeezenet/squeezenet_1.0_gpu.yaml 
```
