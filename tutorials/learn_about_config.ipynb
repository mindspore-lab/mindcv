{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1627f3f2",
   "metadata": {},
   "source": [
    "# 了解模型配置\n",
    "\n",
    "`mindcv`套件可以通过python的`argparse`库和`pyyaml`库解析模型的yaml文件来进行参数的配置，下面我们以squeezenet_1.0模型为例，解释如何配置相应的参数。\n",
    "\n",
    "\n",
    "## 基础环境\n",
    "\n",
    "1. 参数说明\n",
    "\n",
    "- mode: 使用静态图模式（0）或动态图模式（1）。\n",
    "\n",
    "- distribute: 是否使用分布式。\n",
    "\n",
    "\n",
    "2. yaml文件样例\n",
    "\n",
    "```text\n",
    "mode: 0 \n",
    "distribute: True \n",
    "...\n",
    "```\n",
    "\n",
    "3. parse参数设置\n",
    "\n",
    "```text \n",
    "python train.py --mode 0 --distribute False ...\n",
    "```\n",
    "\n",
    "4. 对应的代码示例\n",
    "\n",
    "> `args.model`代表参数`mode`, `args.distribute`代表参数`distribute`。\n",
    "\n",
    "```python\n",
    "def train(args):\n",
    "    ms.set_context(mode=args.mode)\n",
    "\n",
    "    if args.distribute:\n",
    "        init()\n",
    "        device_num = get_group_size()\n",
    "        rank_id = get_rank()\n",
    "        ms.set_auto_parallel_context(device_num=device_num,\n",
    "                                     parallel_mode='data_parallel',\n",
    "                                     gradients_mean=True)\n",
    "    else:\n",
    "        device_num = None\n",
    "        rank_id = None\n",
    "    ...\n",
    "```\n",
    "\n",
    "\n",
    "## 数据集\n",
    "\n",
    "1. 参数说明\n",
    "\n",
    "- dataset: 数据集名称。\n",
    "\n",
    "- data_dir: 数据集文件所在路径。\n",
    "\n",
    "- shuffle: 是否进行数据混洗。\n",
    "\n",
    "- dataset_download: 是否下载数据集。\n",
    "\n",
    "- batch_size: 每个批处理数据包含的数据条目。\n",
    "\n",
    "- drop_remainder: 当最后一个批处理数据包含的数据条目小于 batch_size 时，是否将该批处理丢弃。\n",
    "\n",
    "- num_parallel_workers: 读取数据的工作线程数。\n",
    "\n",
    "2. yaml文件样例\n",
    "\n",
    "```text\n",
    "dataset: 'imagenet'\n",
    "data_dir: './imagenet2012'\n",
    "shuffle: True\n",
    "dataset_download: False\n",
    "batch_size: 32\n",
    "drop_remainder: True \n",
    "num_parallel_workers: 8\n",
    "...\n",
    "```\n",
    "\n",
    "3. parse参数设置\n",
    "\n",
    "```text \n",
    "python train.py ... --dataset imagenet --data_dir ./imagenet2012 --shuffle True \\\n",
    "            --dataset_download False --batch_size 32 --drop_remainder True \\\n",
    "            --num_parallel_workers 8 ...\n",
    "```\n",
    "\n",
    "4. 对应的代码示例\n",
    "\n",
    "```python\n",
    "def train(args):\n",
    "    ...\n",
    "    dataset_train = create_dataset(\n",
    "        name=args.dataset,\n",
    "        root=args.data_dir,\n",
    "        split='train',\n",
    "        shuffle=args.shuffle,\n",
    "        num_samples=args.num_samples,\n",
    "        num_shards=device_num,\n",
    "        shard_id=rank_id,\n",
    "        num_parallel_workers=args.num_parallel_workers,\n",
    "        download=args.dataset_download)\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    loader_train = create_loader(\n",
    "        dataset=dataset_train,\n",
    "        batch_size=args.batch_size,\n",
    "        drop_remainder=args.drop_remainder,\n",
    "        is_training=True,\n",
    "        mixup=args.mixup,\n",
    "        num_classes=args.num_classes,\n",
    "        transform=transform_list,\n",
    "        num_parallel_workers=args.num_parallel_workers,\n",
    "    )\n",
    "    \n",
    "    ...\n",
    "```\n",
    "\n",
    "## 数据增强\n",
    "\n",
    "1. 参数说明\n",
    "\n",
    "- image_resize: 图像的输出尺寸大小。\n",
    "\n",
    "- scale: 要裁剪的原始尺寸大小的各个尺寸的范围。\n",
    "\n",
    "- ratio: 裁剪宽高比的范围。\n",
    "\n",
    "- hfilp: 图像被翻转的概率。\n",
    "\n",
    "- interpolation: 图像插值方式。\n",
    "\n",
    "- crop_pct: 输入图像中心裁剪百分比。\n",
    "\n",
    "- color_jitter: 颜色抖动因子（亮度调整因子，对比度调整因子，饱和度调整因子）。\n",
    "\n",
    "- re_prob: 执行随机擦除的概率。\n",
    "\n",
    "2. yaml文件样例\n",
    "\n",
    "```text\n",
    "image_resize: 224\n",
    "scale: [0.08, 1.0]\n",
    "ratio: [0.75, 1.333]\n",
    "hflip: 0.5\n",
    "interpolation: 'bilinear'\n",
    "crop_pct: 0.875\n",
    "color_jitter: [0.4, 0.4, 0.4]\n",
    "re_prob: 0.5\n",
    "...\n",
    "```\n",
    "\n",
    "3. parse参数设置\n",
    "\n",
    "```text\n",
    "python train.py ... --image_resize 224 --scale [0.08, 1.0] --ratio [0.75, 1.333] \\\n",
    "            --hflip 0.5 --interpolation \"bilinear\" --crop_pct 0.875 \\\n",
    "            --color_jitter [0.4, 0.4, 0.4] --re_prob 0.5 ...\n",
    "```\n",
    "\n",
    "4. 对应的代码示例\n",
    "\n",
    "```python\n",
    "def train(args):\n",
    "    ...\n",
    "    transform_list = create_transforms(\n",
    "        dataset_name=args.dataset,\n",
    "        is_training=True,\n",
    "        image_resize=args.image_resize,\n",
    "        scale=args.scale,\n",
    "        ratio=args.ratio,\n",
    "        hflip=args.hflip,\n",
    "        vflip=args.vflip,\n",
    "        color_jitter=args.color_jitter,\n",
    "        interpolation=args.interpolation,\n",
    "        auto_augment=args.auto_augment,\n",
    "        mean=args.mean,\n",
    "        std=args.std,\n",
    "        re_prob=args.re_prob,\n",
    "        re_scale=args.re_scale,\n",
    "        re_ratio=args.re_ratio,\n",
    "        re_value=args.re_value,\n",
    "        re_max_attempts=args.re_max_attempts\n",
    "    )\n",
    "    ...\n",
    "```\n",
    "\n",
    "## 模型\n",
    "\n",
    "1. 参数说明\n",
    "\n",
    "- model: 模型名称。\n",
    "\n",
    "- num_classes: 分类的类别数。\n",
    "\n",
    "- pretrained: 是否加载预训练模型。\n",
    "\n",
    "- ckpt_path: 参数文件所在的路径。\n",
    "\n",
    "- keep_checkpoint_max: 最多保存多少个checkpoint文件。\n",
    "\n",
    "- ckpt_save_dir: 保存参数文件的路径。\n",
    "\n",
    "- epoch_size: 训练执行轮次。\n",
    "\n",
    "- dataset_sink_mode: 数据是否直接下沉至处理器进行处理。\n",
    "\n",
    "- amp_level: 混合精度等级。\n",
    "\n",
    "2. yaml文件样例\n",
    "\n",
    "```text\n",
    "model: 'squeezenet1_0'\n",
    "num_classes: 1000\n",
    "pretrained: False\n",
    "ckpt_path: './squeezenet1_0_gpu.ckpt'\n",
    "keep_checkpoint_max: 10\n",
    "ckpt_save_dir: './ckpt/'\n",
    "epoch_size: 200\n",
    "dataset_sink_mode: True\n",
    "amp_level: 'O0'\n",
    "...\n",
    "```\n",
    "\n",
    "3. parse参数设置\n",
    "\n",
    "```text\n",
    "python train.py ... --model squeezenet1_0 --num_classes 1000 --pretrained False \\\n",
    "            --ckpt_path ./squeezenet1_0_gpu.ckpt --keep_checkpoint_max 10 \\\n",
    "            --ckpt_save_path ./ckpt/ --epoch_size 200 --dataset_sink_mode True \\\n",
    "            --amp_level O0 ...\n",
    "```\n",
    "\n",
    "4. 对应的代码示例\n",
    "\n",
    "```python\n",
    "def train(args):\n",
    "    ...\n",
    "    network = create_model(model_name=args.model,\n",
    "                    num_classes=args.num_classes,\n",
    "                    in_channels=args.in_channels,\n",
    "                    drop_rate=args.drop_rate,\n",
    "                    drop_path_rate=args.drop_path_rate,\n",
    "                    pretrained=args.pretrained,\n",
    "                    checkpoint_path=args.ckpt_path)\n",
    "    ...\n",
    "```\n",
    "\n",
    "## 损失函数\n",
    "\n",
    "1. 参数说明\n",
    "\n",
    "- loss: 损失函数的简称。\n",
    "\n",
    "- label_smoothing: 标签平滑值，用于计算Loss时防止模型过拟合的正则化手段。\n",
    "\n",
    "2. yaml文件样例\n",
    "\n",
    "```text\n",
    "loss: 'CE'\n",
    "label_smoothing: 0.1\n",
    "...\n",
    "```\n",
    "\n",
    "3. parse参数设置\n",
    "\n",
    "```text\n",
    "python train.py ... --loss CE --label_smoothing 0.1 ...\n",
    "```\n",
    "\n",
    "4. 对应的代码示例\n",
    "\n",
    "```python\n",
    "def train(args):\n",
    "    ...\n",
    "    loss = create_loss(name=args.loss,\n",
    "                 reduction=args.reduction,\n",
    "                 label_smoothing=args.label_smoothing,\n",
    "                 aux_factor=args.aux_factor)\n",
    "    ...\n",
    "```\n",
    "\n",
    "## 学习率策略\n",
    "\n",
    "1. 参数说明\n",
    "\n",
    "- scheduler: 学习率策略的名称。\n",
    "\n",
    "- min_lr: 学习率的最小值。\n",
    "\n",
    "- lr: 学习率的最大值。\n",
    "\n",
    "- warmup_epochs: 学习率warmup的轮次。\n",
    "\n",
    "- decay_epochs: 进行衰减的step数。\n",
    "\n",
    "2. yaml文件样例\n",
    "\n",
    "```text\n",
    "scheduler: 'warmup_cosine_decay'\n",
    "min_lr: 0.0\n",
    "lr: 0.01\n",
    "warmup_epochs: 0\n",
    "decay_epochs: 200\n",
    "...\n",
    "```\n",
    "\n",
    "3. parse参数设置\n",
    "\n",
    "```text\n",
    "python train.py ... --scheduler warmup_cosine_decay --min_lr 0.0 --lr 0.01 \\\n",
    "             --warmup_epochs 0 --decay_epochs 200 ...\n",
    "```\n",
    "\n",
    "4. 对应的代码示例\n",
    "\n",
    "```python\n",
    "def train(args):\n",
    "    ...\n",
    "    lr_scheduler = create_scheduler(steps_per_epoch,\n",
    "                          scheduler=args.scheduler,\n",
    "                          lr=args.lr,\n",
    "                          min_lr=args.min_lr,\n",
    "                          warmup_epochs=args.warmup_epochs,\n",
    "                          decay_epochs=args.decay_epochs,\n",
    "                          decay_rate=args.decay_rate)\n",
    "    ...\n",
    "```\n",
    "\n",
    "\n",
    "## 优化器\n",
    "\n",
    "1. 参数说明\n",
    "\n",
    "- opt: 优化器名称。\n",
    "\n",
    "- filter_bias_and_bn: 参数中是否包含bias，gamma或者beta。\n",
    "\n",
    "- momentum: 移动平均的动量。\n",
    "\n",
    "- weight_decay: 权重衰减（L2 penalty）。\n",
    "\n",
    "- loss_scale: 梯度缩放系数\n",
    "\n",
    "- use_nesterov: 是否使用Nesterov Accelerated Gradient (NAG)算法更新梯度。\n",
    "\n",
    "2. yaml文件样例\n",
    "\n",
    "```text\n",
    "opt: 'momentum'\n",
    "filter_bias_and_bn: True\n",
    "momentum: 0.9\n",
    "weight_decay: 0.00007\n",
    "loss_scale: 1024\n",
    "use_nesterov: False\n",
    "...\n",
    "```\n",
    "\n",
    "3. parse参数设置\n",
    "\n",
    "```text\n",
    "python train.py ... --opt momentum --filter_bias_and_bn True --weight_decay 0.00007 \\\n",
    "              --loss_scale 1024 --use_nesterov False ...\n",
    "```\n",
    "\n",
    "4. 对应的代码示例\n",
    "\n",
    "```python\n",
    "def train(args):\n",
    "    ...\n",
    "    optimizer = create_optimizer(network.trainable_params(),\n",
    "                        opt=args.opt,\n",
    "                        lr=lr_scheduler,\n",
    "                        weight_decay=args.weight_decay,\n",
    "                        momentum=args.momentum,\n",
    "                        nesterov=args.use_nesterov,\n",
    "                        filter_bias_and_bn=args.filter_bias_and_bn,\n",
    "                        loss_scale=args.loss_scale)\n",
    "    ...\n",
    "```\n",
    "\n",
    "\n",
    "## Yaml和Parse组合使用\n",
    "\n",
    "使用parse设置参数可以覆盖yaml文件中的参数设置。以下面的shell命令为例，\n",
    "\n",
    "```shell\n",
    "python train.py -c ./configs/squeezenet/squeezenet_1.0_gpu.yaml --data_dir ./data\n",
    "```\n",
    "上面的命令将`args.data_dir`参数的值由yaml文件中的\"./imagenet2012\"覆盖为\"./data\"。\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
